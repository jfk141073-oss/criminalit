{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48bc098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.stats as stats \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14d7104",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('projet_finale_vf2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92f1f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb1096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['Unnamed: 0'],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cac3e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('nombre de lignes & de colonnes')\n",
    "print(df.shape)\n",
    "print('***********************************************')\n",
    "print('descriptif du dataframe')\n",
    "print(df.describe(include='all'))\n",
    "print('***********************************************')\n",
    "print('nombre de valeurs null')\n",
    "print(df.isnull().sum().sum())\n",
    "if df.isnull().sum().sum()!=0:\n",
    "    print('nombre de valeur null par colonne')\n",
    "    print(df.isnull().sum())\n",
    "print('***********************************************')\n",
    "print('aperçu des 5 premières lignes')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03511d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['departement','revenu_moyen'],axis=1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0740376d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed077f2f",
   "metadata": {},
   "source": [
    "### caractéristiques TreeRegressor modèle V4\n",
    "#max_depth=5,          # profondeur maximale de l’arbre\n",
    "#min_samples_split=5, # min d’échantillons pour un split\n",
    "#min_samples_leaf=1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4b496a",
   "metadata": {},
   "source": [
    "##PREPROCESSING - Modèle Socio-eco (mse1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c57799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT dataset into X and Y\n",
    "\n",
    "features_list_mse1=['tx_pauvrete', 'revenu_median', 'tx_chomage', 'tx_urbanisation', 'densite_2018_(hab/km²)', 'tx_scolarisation_pop']\n",
    "\n",
    "print('Splitting dataset into X and Y...')\n",
    "X_mse1=df[features_list_mse1]\n",
    "\n",
    "y_mse1=df['tx_crim_pour_100 M_hab']\n",
    "print('...Done.')\n",
    "\n",
    "#SPLIT dataset into train test and test...\n",
    "print('Splitting dataset into train test and test...')\n",
    "X_mse1_train,X_mse1_test,y_mse1_train,y_mse1_test=train_test_split(X_mse1,y_mse1,\n",
    "                                                               test_size=0.2,\n",
    "                                                               random_state=0\n",
    "                                                               )\n",
    "print('...Done.')\n",
    "\n",
    "### Training pipeline ###\n",
    "print('---Training pipeline---')\n",
    "\n",
    "# Before preprocessing\n",
    "print(\"#### X_train BEFORE preprocessing ####\")\n",
    "print(X_mse1_train.head())  \n",
    "print()\n",
    "\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "#Preprocessing\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "# Apply ColumnTransformer to create a pipeline that will apply the above preprocessing\n",
    "\n",
    "feature_encoder = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, features_list_mse1)\n",
    "    ],\n",
    ")\n",
    "\n",
    "X_mse1_train=feature_encoder.fit_transform(X_mse1_train)\n",
    "X_mse1_test=feature_encoder.transform(X_mse1_test)\n",
    "\n",
    "#Vérification\n",
    "print('...Done.')\n",
    "print(\"#### X_mse_train AFTER preprocessing ####\")\n",
    "print(X_mse1_train[0:5, :])  # affiche les 5 premières lignes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a7e664",
   "metadata": {},
   "source": [
    "#BUILD MODEL(mse1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d30da98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model\n",
    "print(\"Training model...\")\n",
    "regressor = DecisionTreeRegressor(\n",
    "    random_state=0,\n",
    "    max_depth=5,          # profondeur maximale de l’arbre\n",
    "    min_samples_split=5, # min d’échantillons pour un split\n",
    "    min_samples_leaf=1   # min d’échantillons dans une feuille\n",
    "    )\n",
    "regressor.fit(X_mse1_train, y_mse1_train)\n",
    "print(\"...Done.\")\n",
    "\n",
    "# Predictions on training set\n",
    "print(\"Predictions on train set...\")\n",
    "y_mse1_train_pred = regressor.predict(X_mse1_train)\n",
    "print(\"...Done.\")\n",
    "print()\n",
    "\n",
    "# Afficher les 5 premières prédictions train vs valeurs réelles\n",
    "for vrai, pred in zip(y_mse1_train[:5], y_mse1_train_pred[:5]):\n",
    "    print(f\"Réel: {vrai:.2f}  →  Prédit: {pred:.2f}\")\n",
    "\n",
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "y_mse1_test_pred = regressor.predict(X_mse1_test)\n",
    "print(\"...Done.\")\n",
    "\n",
    "# Afficher les 5 premières prédictions test vs valeurs réelles\n",
    "for vrai, pred in zip(y_mse1_test[:5], y_mse1_test_pred[:5]):\n",
    "    print(f\"Réel: {vrai:.2f}  →  Prédit: {pred:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbde0d8",
   "metadata": {},
   "source": [
    "#EVALUATE MODEL(mse1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d481529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance assessment\n",
    "print(\"--- Assessing the performances of the model ---\")\n",
    "\n",
    "r2_train_mse1=regressor.score(X_mse1_train, y_mse1_train)\n",
    "r2_test_mse1=regressor.score(X_mse1_test, y_mse1_test)\n",
    "\n",
    "# Print R^2 scores\n",
    "print(\"R2 score on training set : \", r2_train_mse1)\n",
    "print(\"R2 score on test set : \", r2_test_mse1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05be7d03",
   "metadata": {},
   "source": [
    "#Features Importance(mse1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50cd56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance assessment\n",
    "\n",
    "importance_mse1 = pd.Series(regressor.feature_importances_, index=features_list_mse1)\n",
    "importance_mse1.sort_values(ascending=False, inplace=True)\n",
    "print(\"Importance des features :\")\n",
    "print(importance_mse1)\n",
    "\n",
    "df_imp_mse1 = importance_mse1.reset_index()\n",
    "df_imp_mse1.columns = ['Feature', 'Importance']\n",
    "df_imp_mse1['Model'] = 'MSE1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c08ce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisation Importance\n",
    "importance_mse1.plot(kind='barh')\n",
    "plt.title(\"Importance des features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82cdb4d",
   "metadata": {},
   "source": [
    "##PREPROCESSING - Modèle Socio-eco (mse2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ce3748",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT dataset into X and Y\n",
    "\n",
    "features_list_mse2=['tx_pauvrete', 'revenu_median', 'tx_chomage', 'tx_urbanisation', 'densite_2018_(hab/km²)', 'tx_pop_sans_dipl']\n",
    "\n",
    "print('Splitting dataset into X and Y...')\n",
    "X_mse2=df[features_list_mse2]\n",
    "\n",
    "y_mse2=df['tx_crim_pour_100 M_hab']\n",
    "print('...Done.')\n",
    "\n",
    "#SPLIT dataset into train test and test...\n",
    "print('Splitting dataset into train test and test...')\n",
    "X_mse2_train,X_mse2_test,y_mse2_train,y_mse2_test=train_test_split(X_mse2,y_mse2,\n",
    "                                                               test_size=0.2,\n",
    "                                                               random_state=0\n",
    "                                                               )\n",
    "print('...Done.')\n",
    "\n",
    "### Training pipeline ###\n",
    "print('---Training pipeline---')\n",
    "\n",
    "# Before preprocessing\n",
    "print(\"#### X_train BEFORE preprocessing ####\")\n",
    "print(X_mse2_train.head())  \n",
    "print()\n",
    "\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "#Preprocessing\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "# Apply ColumnTransformer to create a pipeline that will apply the above preprocessing\n",
    "\n",
    "feature_encoder = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, features_list_mse2)\n",
    "    ],\n",
    ")\n",
    "\n",
    "X_mse2_train=feature_encoder.fit_transform(X_mse2_train)\n",
    "X_mse2_test=feature_encoder.transform(X_mse2_test)\n",
    "\n",
    "#Vérification\n",
    "print('...Done.')\n",
    "print(\"#### X_mse_train AFTER preprocessing ####\")\n",
    "print(X_mse2_train[0:5, :])  # affiche les 5 premières lignes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e34b127",
   "metadata": {},
   "source": [
    "#BUILD MODEL(mse2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897d24fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model\n",
    "print(\"Training model...\")\n",
    "regressor = DecisionTreeRegressor(\n",
    "    random_state=0,\n",
    "    max_depth=5,          # profondeur maximale de l’arbre\n",
    "    min_samples_split=5, # min d’échantillons pour un split\n",
    "    min_samples_leaf=1   # min d’échantillons dans une feuille\n",
    "    )\n",
    "regressor.fit(X_mse2_train, y_mse2_train)\n",
    "print(\"...Done.\")\n",
    "\n",
    "# Predictions on training set\n",
    "print(\"Predictions on train set...\")\n",
    "y_mse2_train_pred = regressor.predict(X_mse2_train)\n",
    "print(\"...Done.\")\n",
    "print()\n",
    "\n",
    "# Afficher les 5 premières prédictions train vs valeurs réelles\n",
    "for vrai, pred in zip(y_mse2_train[:5], y_mse2_train_pred[:5]):\n",
    "    print(f\"Réel: {vrai:.2f}  →  Prédit: {pred:.2f}\")\n",
    "\n",
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "y_mse2_test_pred = regressor.predict(X_mse2_test)\n",
    "print(\"...Done.\")\n",
    "\n",
    "# Afficher les 5 premières prédictions test vs valeurs réelles\n",
    "for vrai, pred in zip(y_mse2_test[:5], y_mse2_test_pred[:5]):\n",
    "    print(f\"Réel: {vrai:.2f}  →  Prédit: {pred:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c434461",
   "metadata": {},
   "source": [
    "#EVALUATE MODEL(mse2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78f6845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance assessment\n",
    "print(\"--- Assessing the performances of the model ---\")\n",
    "\n",
    "r2_train_mse2=regressor.score(X_mse2_train, y_mse2_train)\n",
    "r2_test_mse2=regressor.score(X_mse2_test, y_mse2_test)\n",
    "\n",
    "# Print R^2 scores\n",
    "print(\"R2 score on training set : \", r2_train_mse2)\n",
    "print(\"R2 score on test set : \", r2_test_mse2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2d588b",
   "metadata": {},
   "source": [
    "#Features Importance(mse2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe87031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance assessment\n",
    "\n",
    "importance_mse2 = pd.Series(regressor.feature_importances_, index=features_list_mse2)\n",
    "importance_mse2.sort_values(ascending=False, inplace=True)\n",
    "print(\"Importance des features :\")\n",
    "print(importance_mse2)\n",
    "\n",
    "df_imp_mse2 = importance_mse2.reset_index()\n",
    "df_imp_mse2.columns = ['Feature', 'Importance']\n",
    "df_imp_mse2['Model'] = 'MSE2'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e737fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisation Importance\n",
    "\n",
    "importance_mse2.plot(kind='barh')\n",
    "plt.title(\"Importance des features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418013b8",
   "metadata": {},
   "source": [
    "##PREPROCESSING - Modèle Socio (ms1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bfd6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT dataset into X and Y\n",
    "\n",
    "features_list_ms1=['tx_urbanisation', 'densite_2018_(hab/km²)', 'tx_scolarisation_pop']\n",
    "\n",
    "print('Splitting dataset into X and Y...')\n",
    "X_ms1=df[features_list_ms1]\n",
    "\n",
    "y_ms1=df['tx_crim_pour_100 M_hab']\n",
    "print('...Done.')\n",
    "\n",
    "#SPLIT dataset into train test and test...\n",
    "print('Splitting dataset into train test and test...')\n",
    "X_ms1_train,X_ms1_test,y_ms1_train,y_ms1_test=train_test_split(X_ms1,y_ms1,\n",
    "                                                               test_size=0.2,\n",
    "                                                               random_state=0\n",
    "                                                               )\n",
    "print('...Done.')\n",
    "\n",
    "### Training pipeline ###\n",
    "print('---Training pipeline---')\n",
    "\n",
    "# Before preprocessing\n",
    "print(\"#### X_train BEFORE preprocessing ####\")\n",
    "print(X_ms1_train.head())  \n",
    "print()\n",
    "\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "#Preprocessing\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "# Apply ColumnTransformer to create a pipeline that will apply the above preprocessing\n",
    "\n",
    "feature_encoder = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, features_list_ms1)\n",
    "    ],\n",
    ")\n",
    "\n",
    "X_ms1_train=feature_encoder.fit_transform(X_ms1_train)\n",
    "X_ms1_test=feature_encoder.transform(X_ms1_test)\n",
    "\n",
    "#Vérification\n",
    "print('...Done.')\n",
    "print(\"#### X_ms1_train AFTER preprocessing ####\")\n",
    "print(X_ms1_train[0:5, :])  # affiche les 5 premières lignes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f864db",
   "metadata": {},
   "source": [
    "##BUILD MODEL(ms1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0abad5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model\n",
    "print(\"Training model...\")\n",
    "regressor = DecisionTreeRegressor(\n",
    "    random_state=0,\n",
    "    max_depth=5,          # profondeur maximale de l’arbre\n",
    "    min_samples_split=5, # min d’échantillons pour un split\n",
    "    min_samples_leaf=1   # min d’échantillons dans une feuille\n",
    "    )\n",
    "regressor.fit(X_ms1_train, y_ms1_train)\n",
    "print(\"...Done.\")\n",
    "\n",
    "# Predictions on training set\n",
    "print(\"Predictions on train set...\")\n",
    "y_ms1_train_pred = regressor.predict(X_ms1_train)\n",
    "print(\"...Done.\")\n",
    "print()\n",
    "\n",
    "# Afficher les 5 premières prédictions train vs valeurs réelles\n",
    "for vrai, pred in zip(y_ms1_train[:5], y_ms1_train_pred[:5]):\n",
    "    print(f\"Réel: {vrai:.2f}  →  Prédit: {pred:.2f}\")\n",
    "\n",
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "y_ms1_test_pred = regressor.predict(X_ms1_test)\n",
    "print(\"...Done.\")\n",
    "\n",
    "# Afficher les 5 premières prédictions test vs valeurs réelles\n",
    "for vrai, pred in zip(y_ms1_test[:5], y_ms1_test_pred[:5]):\n",
    "    print(f\"Réel: {vrai:.2f}  →  Prédit: {pred:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41688dbd",
   "metadata": {},
   "source": [
    "#EVALUATE MODEL(ms1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2812f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance assessment\n",
    "print(\"--- Assessing the performances of the model ---\")\n",
    "\n",
    "r2_train_ms1=regressor.score(X_ms1_train, y_ms1_train)\n",
    "r2_test_ms1=regressor.score(X_ms1_test, y_ms1_test)\n",
    "\n",
    "# Print R^2 scores\n",
    "print(\"R2 score on training set : \", r2_train_ms1)\n",
    "print(\"R2 score on test set : \", r2_test_ms1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71e2e5c",
   "metadata": {},
   "source": [
    "#Features Importance(ms1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d02769",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importa,ce assessment\n",
    "\n",
    "importance_ms1 = pd.Series(regressor.feature_importances_, index=features_list_ms1)\n",
    "importance_ms1.sort_values(ascending=False, inplace=True)\n",
    "print(\"Importance des features :\")\n",
    "print(importance_ms1)\n",
    "\n",
    "df_imp_ms1 = importance_ms1.reset_index()\n",
    "df_imp_ms1.columns = ['Feature', 'Importance']\n",
    "df_imp_ms1['Model'] = 'MS1'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb284eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisation Importance\n",
    "\n",
    "importance_ms1.plot(kind='barh')\n",
    "plt.title(\"Importance des features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc75a25",
   "metadata": {},
   "source": [
    "##PREPROCESSING - Modèle Socio (ms2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714dd71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT dataset into X and Y\n",
    "\n",
    "features_list_ms2=['tx_urbanisation', 'densite_2018_(hab/km²)', 'tx_pop_sans_dipl']\n",
    "\n",
    "print('Splitting dataset into X and Y...')\n",
    "X_ms2=df[features_list_ms2]\n",
    "\n",
    "y_ms2=df['tx_crim_pour_100 M_hab']\n",
    "print('...Done.')\n",
    "\n",
    "#SPLIT dataset into train test and test...\n",
    "print('Splitting dataset into train test and test...')\n",
    "X_ms2_train,X_ms2_test,y_ms2_train,y_ms2_test=train_test_split(X_ms2,y_ms2,\n",
    "                                                               test_size=0.2,\n",
    "                                                               random_state=0\n",
    "                                                               )\n",
    "print('...Done.')\n",
    "\n",
    "### Training pipeline ###\n",
    "print('---Training pipeline---')\n",
    "\n",
    "# Before preprocessing\n",
    "print(\"#### X_train BEFORE preprocessing ####\")\n",
    "print(X_ms2_train.head())  \n",
    "print()\n",
    "\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "#Preprocessing\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "# Apply ColumnTransformer to create a pipeline that will apply the above preprocessing\n",
    "\n",
    "feature_encoder = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, features_list_ms2)\n",
    "    ],\n",
    ")\n",
    "\n",
    "X_ms2_train=feature_encoder.fit_transform(X_ms2_train)\n",
    "X_ms2_test=feature_encoder.transform(X_ms2_test)\n",
    "\n",
    "#Vérification\n",
    "print('...Done.')\n",
    "print(\"#### X_ms2_train AFTER preprocessing ####\")\n",
    "print(X_ms2_train[0:5, :])  # affiche les 5 premières lignes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147a7bf4",
   "metadata": {},
   "source": [
    "#BUILD MODEL(ms2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193b1cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model\n",
    "print(\"Training model...\")\n",
    "regressor = DecisionTreeRegressor(\n",
    "    random_state=0,\n",
    "    max_depth=5,          # profondeur maximale de l’arbre\n",
    "    min_samples_split=5, # min d’échantillons pour un split\n",
    "    min_samples_leaf=1   # min d’échantillons dans une feuille\n",
    "                                  )\n",
    "regressor.fit(X_ms2_train, y_ms2_train)\n",
    "print(\"...Done.\")\n",
    "\n",
    "# Predictions on training set\n",
    "print(\"Predictions on train set...\")\n",
    "y_ms2_train_pred = regressor.predict(X_ms2_train)\n",
    "print(\"...Done.\")\n",
    "print()\n",
    "\n",
    "# Afficher les 5 premières prédictions train vs valeurs réelles\n",
    "for vrai, pred in zip(y_ms2_train[:5], y_ms2_train_pred[:5]):\n",
    "    print(f\"Réel: {vrai:.2f}  →  Prédit: {pred:.2f}\")\n",
    "\n",
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "y_ms2_test_pred = regressor.predict(X_ms2_test)\n",
    "print(\"...Done.\")\n",
    "\n",
    "# Afficher les 5 premières prédictions test vs valeurs réelles\n",
    "for vrai, pred in zip(y_ms2_test[:5], y_ms2_test_pred[:5]):\n",
    "    print(f\"Réel: {vrai:.2f}  →  Prédit: {pred:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c5aff0",
   "metadata": {},
   "source": [
    "#EVALUATE MODEL(ms2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6a68b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance assessment\n",
    "print(\"--- Assessing the performances of the model ---\")\n",
    "\n",
    "r2_train_ms2=regressor.score(X_ms2_train, y_ms2_train)\n",
    "r2_test_ms2=regressor.score(X_ms2_test, y_ms2_test)\n",
    "\n",
    "# Print R^2 scores\n",
    "print(\"R2 score on training set : \", r2_train_ms2)\n",
    "print(\"R2 score on test set : \", r2_test_ms2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff29640",
   "metadata": {},
   "source": [
    "#Features Importance(ms2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7789e9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importance assessment\n",
    "\n",
    "importance_ms2 = pd.Series(regressor.feature_importances_, index=features_list_ms2)\n",
    "importance_ms2.sort_values(ascending=False, inplace=True)\n",
    "print(\"Importance des features :\")\n",
    "print(importance_ms2)\n",
    "\n",
    "df_imp_ms2 = importance_ms2.reset_index()\n",
    "df_imp_ms2.columns = ['Feature', 'Importance']\n",
    "df_imp_ms2['Model'] = 'MS2'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43a65dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisation Importance\n",
    "\n",
    "importance_ms2.plot(kind='barh')\n",
    "plt.title(\"Importance des features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af06d0b1",
   "metadata": {},
   "source": [
    "##PREPROCESSING - Modèle Socio + tx chomage (ms1ptc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f0d6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT dataset into X and Y\n",
    "\n",
    "features_list_ms1ptc=['tx_chomage','tx_urbanisation', 'densite_2018_(hab/km²)', 'tx_scolarisation_pop']\n",
    "\n",
    "print('Splitting dataset into X and Y...')\n",
    "X_ms1ptc=df[features_list_ms1ptc]\n",
    "\n",
    "y_ms1ptc=df['tx_crim_pour_100 M_hab']\n",
    "print('...Done.')\n",
    "\n",
    "#SPLIT dataset into train test and test...\n",
    "print('Splitting dataset into train test and test...')\n",
    "X_ms1ptc_train,X_ms1ptc_test,y_ms1ptc_train,y_ms1ptc_test=train_test_split(X_ms1ptc,y_ms1ptc,\n",
    "                                                               test_size=0.2,\n",
    "                                                               random_state=0\n",
    "                                                               )\n",
    "print('...Done.')\n",
    "\n",
    "### Training pipeline ###\n",
    "print('---Training pipeline---')\n",
    "\n",
    "# Before preprocessing\n",
    "print(\"#### X_train BEFORE preprocessing ####\")\n",
    "print(X_ms1ptc_train.head())  \n",
    "print()\n",
    "\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "#Preprocessing\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "# Apply ColumnTransformer to create a pipeline that will apply the above preprocessing\n",
    "\n",
    "feature_encoder = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, features_list_ms1ptc)\n",
    "    ],\n",
    ")\n",
    "\n",
    "X_ms1ptc_train=feature_encoder.fit_transform(X_ms1ptc_train)\n",
    "X_ms1ptc_test=feature_encoder.transform(X_ms1ptc_test)\n",
    "\n",
    "#Vérification\n",
    "print('...Done.')\n",
    "print(\"#### X_ms_train AFTER preprocessing ####\")\n",
    "print(X_ms1ptc_train[0:5, :])  # affiche les 5 premières lignes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4bb46b",
   "metadata": {},
   "source": [
    "#BUILD MODEL(ms1ptc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62676667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model\n",
    "print(\"Training model...\")\n",
    "regressor = DecisionTreeRegressor(\n",
    "    random_state=0,\n",
    "    max_depth=5,          # profondeur maximale de l’arbre\n",
    "    min_samples_split=5, # min d’échantillons pour un split\n",
    "    min_samples_leaf=1   # min d’échantillons dans une feuille\n",
    "    )\n",
    "regressor.fit(X_ms1ptc_train, y_ms1ptc_train)\n",
    "print(\"...Done.\")\n",
    "\n",
    "# Predictions on training set\n",
    "print(\"Predictions on train set...\")\n",
    "y_ms1ptc_train_pred = regressor.predict(X_ms1ptc_train)\n",
    "print(\"...Done.\")\n",
    "print()\n",
    "\n",
    "# Afficher les 5 premières prédictions train vs valeurs réelles\n",
    "for vrai, pred in zip(y_ms1ptc_train[:5], y_ms1ptc_train_pred[:5]):\n",
    "    print(f\"Réel: {vrai:.2f}  →  Prédit: {pred:.2f}\")\n",
    "\n",
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "y_ms1ptc_test_pred = regressor.predict(X_ms1ptc_test)\n",
    "print(\"...Done.\")\n",
    "\n",
    "# Afficher les 5 premières prédictions test vs valeurs réelles\n",
    "for vrai, pred in zip(y_ms1ptc_test[:5], y_ms1ptc_test_pred[:5]):\n",
    "    print(f\"Réel: {vrai:.2f}  →  Prédit: {pred:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6d30cd",
   "metadata": {},
   "source": [
    "#EVALUATE MODEL(ms1ptc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca19e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance assessment\n",
    "print(\"--- Assessing the performances of the model ---\")\n",
    "\n",
    "r2_train_ms1ptc=regressor.score(X_ms1ptc_train, y_ms1ptc_train)\n",
    "r2_test_ms1ptc=regressor.score(X_ms1ptc_test, y_ms1ptc_test)\n",
    "\n",
    "# Print R^2 scores\n",
    "print(\"R2 score on training set : \", r2_train_ms1ptc)\n",
    "print(\"R2 score on test set : \", r2_test_ms1ptc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c9a2f7",
   "metadata": {},
   "source": [
    "#Features Importance (ms1ptc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fcce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importance assessment\n",
    "\n",
    "importance_ms1ptc = pd.Series(regressor.feature_importances_, index=features_list_ms1ptc)\n",
    "importance_ms1ptc.sort_values(ascending=False, inplace=True)\n",
    "print(\"Importance des features :\")\n",
    "print(importance_ms1ptc)\n",
    "\n",
    "df_imp_ms1ptc = importance_ms1ptc.reset_index()\n",
    "df_imp_ms1ptc.columns = ['Feature', 'Importance']\n",
    "df_imp_ms1ptc['Model'] = 'MS1PTC'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdba439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisation Importance\n",
    "\n",
    "importance_ms1ptc.plot(kind='barh')\n",
    "plt.title(\"Importance des features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac402dd",
   "metadata": {},
   "source": [
    "##PREPROCESSING - Modèle Socio + tx chomage (ms2ptc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e45ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT dataset into X and Y\n",
    "\n",
    "features_list_ms2ptc=['tx_chomage','tx_urbanisation', 'densite_2018_(hab/km²)', 'tx_pop_sans_dipl']\n",
    "\n",
    "print('Splitting dataset into X and Y...')\n",
    "X_ms2ptc=df[features_list_ms2ptc]\n",
    "\n",
    "y_ms2ptc=df['tx_crim_pour_100 M_hab']\n",
    "print('...Done.')\n",
    "\n",
    "#SPLIT dataset into train test and test...\n",
    "print('Splitting dataset into train test and test...')\n",
    "X_ms2ptc_train,X_ms2ptc_test,y_ms2ptc_train,y_ms2ptc_test=train_test_split(X_ms2ptc,y_ms2ptc,\n",
    "                                                               test_size=0.2,\n",
    "                                                               random_state=0\n",
    "                                                               )\n",
    "print('...Done.')\n",
    "\n",
    "### Training pipeline ###\n",
    "print('---Training pipeline---')\n",
    "\n",
    "# Before preprocessing\n",
    "print(\"#### X_train BEFORE preprocessing ####\")\n",
    "print(X_ms2ptc_train.head())  \n",
    "print()\n",
    "\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "#Preprocessing\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "# Apply ColumnTransformer to create a pipeline that will apply the above preprocessing\n",
    "\n",
    "feature_encoder = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, features_list_ms2ptc)\n",
    "    ],\n",
    ")\n",
    "\n",
    "X_ms2ptc_train=feature_encoder.fit_transform(X_ms2ptc_train)\n",
    "X_ms2ptc_test=feature_encoder.transform(X_ms2ptc_test)\n",
    "\n",
    "#Vérification\n",
    "print('...Done.')\n",
    "print(\"#### X_ms_train AFTER preprocessing ####\")\n",
    "print(X_ms2ptc_train[0:5, :])  # affiche les 5 premières lignes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102ba8c6",
   "metadata": {},
   "source": [
    "#BUILD MODEL(ms2ptc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c297ec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model\n",
    "print(\"Training model...\")\n",
    "regressor = DecisionTreeRegressor(\n",
    "    random_state=0,\n",
    "    max_depth=5,          # profondeur maximale de l’arbre\n",
    "    min_samples_split=5, # min d’échantillons pour un split\n",
    "    min_samples_leaf=1   # min d’échantillons dans une feuille\n",
    ")\n",
    "regressor.fit(X_ms2ptc_train, y_ms2ptc_train)\n",
    "print(\"...Done.\")\n",
    "\n",
    "# Predictions on training set\n",
    "print(\"Predictions on train set...\")\n",
    "y_ms2ptc_train_pred = regressor.predict(X_ms2ptc_train)\n",
    "print(\"...Done.\")\n",
    "print()\n",
    "\n",
    "# Afficher les 5 premières prédictions train vs valeurs réelles\n",
    "for vrai, pred in zip(y_ms2ptc_train[:5], y_ms2ptc_train_pred[:5]):\n",
    "    print(f\"Réel: {vrai:.2f}  →  Prédit: {pred:.2f}\")\n",
    "\n",
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "y_ms2ptc_test_pred = regressor.predict(X_ms2ptc_test)\n",
    "print(\"...Done.\")\n",
    "\n",
    "# Afficher les 5 premières prédictions test vs valeurs réelles\n",
    "for vrai, pred in zip(y_ms2ptc_test[:5], y_ms2ptc_test_pred[:5]):\n",
    "    print(f\"Réel: {vrai:.2f}  →  Prédit: {pred:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624099b5",
   "metadata": {},
   "source": [
    "#EVALUATE MODEL(ms2ptc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1f4b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance assessment\n",
    "print(\"--- Assessing the performances of the model ---\")\n",
    "\n",
    "r2_train_ms2ptc=regressor.score(X_ms2ptc_train, y_ms2ptc_train)\n",
    "r2_test_ms2ptc=regressor.score(X_ms2ptc_test, y_ms2ptc_test)\n",
    "\n",
    "# Print R^2 scores\n",
    "print(\"R2 score on training set : \", r2_train_ms2ptc)\n",
    "print(\"R2 score on test set : \", r2_test_ms2ptc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7fdfff",
   "metadata": {},
   "source": [
    "#Features Importance (ms2ptc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dc7375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance assessment\n",
    "\n",
    "importance_ms2ptc = pd.Series(regressor.feature_importances_, index=features_list_ms2ptc)\n",
    "importance_ms2ptc.sort_values(ascending=False, inplace=True)\n",
    "print(\"Importance des features :\")\n",
    "print(importance_ms2ptc)\n",
    "\n",
    "df_imp_ms2ptc = importance_ms2ptc.reset_index()\n",
    "df_imp_ms2ptc.columns = ['Feature', 'Importance']\n",
    "df_imp_ms2ptc['Model'] = 'MS2PTC'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bb1247",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisation Importance\n",
    "\n",
    "importance_ms2ptc.plot(kind='barh')\n",
    "plt.title(\"Importance des features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b062353e",
   "metadata": {},
   "source": [
    "##PREPROCESSING - Modèle Socio + tx pauvrete (ms1ptp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067e254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT dataset into X and Y\n",
    "\n",
    "features_list_ms1ptp=['tx_pauvrete','tx_urbanisation', 'densite_2018_(hab/km²)', 'tx_scolarisation_pop']\n",
    "\n",
    "print('Splitting dataset into X and Y...')\n",
    "X_ms1ptp=df[features_list_ms1ptp]\n",
    "\n",
    "y_ms1ptp=df['tx_crim_pour_100 M_hab']\n",
    "print('...Done.')\n",
    "\n",
    "#SPLIT dataset into train test and test...\n",
    "print('Splitting dataset into train test and test...')\n",
    "X_ms1ptp_train,X_ms1ptp_test,y_ms1ptp_train,y_ms1ptp_test=train_test_split(X_ms1ptp,y_ms1ptp,\n",
    "                                                               test_size=0.2,\n",
    "                                                               random_state=0\n",
    "                                                               )\n",
    "print('...Done.')\n",
    "\n",
    "### Training pipeline ###\n",
    "print('---Training pipeline---')\n",
    "\n",
    "# Before preprocessing\n",
    "print(\"#### X_train BEFORE preprocessing ####\")\n",
    "print(X_ms1ptp_train.head())  \n",
    "print()\n",
    "\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "#Preprocessing\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "# Apply ColumnTransformer to create a pipeline that will apply the above preprocessing\n",
    "\n",
    "feature_encoder = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, features_list_ms1ptp)\n",
    "    ],\n",
    ")\n",
    "\n",
    "X_ms1ptp_train=feature_encoder.fit_transform(X_ms1ptp_train)\n",
    "X_ms1ptp_test=feature_encoder.transform(X_ms1ptp_test)\n",
    "\n",
    "#Vérification\n",
    "print('...Done.')\n",
    "print(\"#### X_ms_train AFTER preprocessing ####\")\n",
    "print(X_ms1ptp_train[0:5, :])  # affiche les 5 premières lignes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b897f947",
   "metadata": {},
   "source": [
    "#BUILD MODEL(ms1ptp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6ebc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model\n",
    "print(\"Training model...\")\n",
    "regressor = DecisionTreeRegressor(\n",
    "    random_state=0,\n",
    "    max_depth=5,          # profondeur maximale de l’arbre\n",
    "    min_samples_split=5, # min d’échantillons pour un split\n",
    "    min_samples_leaf=1   # min d’échantillons dans une feuille\n",
    ")\n",
    "regressor.fit(X_ms1ptp_train, y_ms1ptp_train)\n",
    "print(\"...Done.\")\n",
    "\n",
    "# Predictions on training set\n",
    "print(\"Predictions on train set...\")\n",
    "y_ms1ptp_train_pred = regressor.predict(X_ms1ptp_train)\n",
    "print(\"...Done.\")\n",
    "print()\n",
    "\n",
    "# Afficher les 5 premières prédictions train vs valeurs réelles\n",
    "for vrai, pred in zip(y_ms1ptp_train[:5], y_ms1ptp_train_pred[:5]):\n",
    "    print(f\"Réel: {vrai:.2f}  →  Prédit: {pred:.2f}\")\n",
    "\n",
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "y_ms1ptp_test_pred = regressor.predict(X_ms1ptp_test)\n",
    "print(\"...Done.\")\n",
    "\n",
    "# Afficher les 5 premières prédictions test vs valeurs réelles\n",
    "for vrai, pred in zip(y_ms1ptp_test[:5], y_ms1ptp_test_pred[:5]):\n",
    "    print(f\"Réel: {vrai:.2f}  →  Prédit: {pred:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4434e532",
   "metadata": {},
   "source": [
    "#EVALUATE MODEL(ms1ptp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be14d532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance assessment\n",
    "print(\"--- Assessing the performances of the model ---\")\n",
    "\n",
    "r2_train_ms1ptp=regressor.score(X_ms1ptp_train, y_ms1ptp_train)\n",
    "r2_test_ms1ptp=regressor.score(X_ms1ptp_test, y_ms1ptp_test)\n",
    "\n",
    "# Print R^2 scores\n",
    "print(\"R2 score on training set : \", r2_train_ms1ptp)\n",
    "print(\"R2 score on test set : \", r2_test_ms1ptp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe6de38",
   "metadata": {},
   "source": [
    "#Features Importance (ms1ptp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88724f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance assessment\n",
    "\n",
    "importance_ms1ptp = pd.Series(regressor.feature_importances_, index=features_list_ms1ptp)\n",
    "importance_ms1ptp.sort_values(ascending=False, inplace=True)\n",
    "print(\"Importance des features :\")\n",
    "print(importance_ms1ptp)\n",
    "\n",
    "df_imp_ms1ptp = importance_ms1ptp.reset_index()\n",
    "df_imp_ms1ptp.columns = ['Feature', 'Importance']\n",
    "df_imp_ms1ptp['Model'] = 'MS1PTP'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09da5ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualisation Importance\n",
    "importance_ms1ptp.plot(kind='barh')\n",
    "plt.title(\"Importance des features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c58614",
   "metadata": {},
   "source": [
    "##PREPROCESSING - Modèle Socio + tx pauvrete (ms2ptp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c06ecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT dataset into X and Y\n",
    "\n",
    "features_list_ms2ptp=['tx_pauvrete','tx_urbanisation', 'densite_2018_(hab/km²)', 'tx_scolarisation_pop']\n",
    "\n",
    "print('Splitting dataset into X and Y...')\n",
    "X_ms2ptp=df[features_list_ms2ptp]\n",
    "\n",
    "y_ms2ptp=df['tx_crim_pour_100 M_hab']\n",
    "print('...Done.')\n",
    "\n",
    "#SPLIT dataset into train test and test...\n",
    "print('Splitting dataset into train test and test...')\n",
    "X_ms2ptp_train,X_ms2ptp_test,y_ms2ptp_train,y_ms2ptp_test=train_test_split(X_ms2ptp,y_ms2ptp,\n",
    "                                                               test_size=0.2,\n",
    "                                                               random_state=0\n",
    "                                                               )\n",
    "print('...Done.')\n",
    "\n",
    "### Training pipeline ###\n",
    "print('---Training pipeline---')\n",
    "\n",
    "# Before preprocessing\n",
    "print(\"#### X_train BEFORE preprocessing ####\")\n",
    "print(X_ms2ptp_train.head())  \n",
    "print()\n",
    "\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "#Preprocessing\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "# Apply ColumnTransformer to create a pipeline that will apply the above preprocessing\n",
    "\n",
    "feature_encoder = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, features_list_ms2ptp)\n",
    "    ],\n",
    ")\n",
    "\n",
    "X_ms2ptp_train=feature_encoder.fit_transform(X_ms2ptp_train)\n",
    "X_ms2ptp_test=feature_encoder.transform(X_ms2ptp_test)\n",
    "\n",
    "#Vérification\n",
    "print('...Done.')\n",
    "print(\"#### X_ms_train AFTER preprocessing ####\")\n",
    "print(X_ms2ptp_train[0:5, :])  # affiche les 5 premières lignes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32329ae5",
   "metadata": {},
   "source": [
    "#BUILD MODEL(ms2ptp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8270cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model\n",
    "print(\"Training model...\")\n",
    "regressor = DecisionTreeRegressor(\n",
    "    random_state=0,\n",
    "    max_depth=5,          # profondeur maximale de l’arbre\n",
    "    min_samples_split=5, # min d’échantillons pour un split\n",
    "    min_samples_leaf=1   # min d’échantillons dans une feuille\n",
    ")\n",
    "regressor.fit(X_ms2ptp_train, y_ms2ptp_train)\n",
    "print(\"...Done.\")\n",
    "\n",
    "# Predictions on training set\n",
    "print(\"Predictions on train set...\")\n",
    "y_ms2ptp_train_pred = regressor.predict(X_ms2ptp_train)\n",
    "print(\"...Done.\")\n",
    "print()\n",
    "\n",
    "# Afficher les 5 premières prédictions train vs valeurs réelles\n",
    "for vrai, pred in zip(y_ms2ptp_train[:5], y_ms2ptp_train_pred[:5]):\n",
    "    print(f\"Réel: {vrai:.2f}  →  Prédit: {pred:.2f}\")\n",
    "\n",
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "y_ms2ptp_test_pred = regressor.predict(X_ms2ptp_test)\n",
    "print(\"...Done.\")\n",
    "\n",
    "# Afficher les 5 premières prédictions test vs valeurs réelles\n",
    "for vrai, pred in zip(y_ms2ptp_test[:5], y_ms2ptp_test_pred[:5]):\n",
    "    print(f\"Réel: {vrai:.2f}  →  Prédit: {pred:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0475eb8",
   "metadata": {},
   "source": [
    "#EVALUATE MODEL(ms2ptp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ac805e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance assessment\n",
    "print(\"--- Assessing the performances of the model ---\")\n",
    "\n",
    "r2_train_ms2ptp=regressor.score(X_ms2ptp_train, y_ms2ptp_train)\n",
    "r2_test_ms2ptp=regressor.score(X_ms2ptp_test, y_ms2ptp_test)\n",
    "\n",
    "# Print R^2 scores\n",
    "print(\"R2 score on training set : \", r2_train_ms2ptp)\n",
    "print(\"R2 score on test set : \", r2_test_ms2ptp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da53840",
   "metadata": {},
   "source": [
    "#Features Importance (ms2ptp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f8650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance assessment\n",
    "\n",
    "importance_ms2ptp = pd.Series(regressor.feature_importances_, index=features_list_ms2ptp)\n",
    "importance_ms2ptp.sort_values(ascending=False, inplace=True)\n",
    "print(\"Importance des features :\")\n",
    "print(importance_ms2ptp)\n",
    "\n",
    "df_imp_ms2ptp = importance_ms2ptp.reset_index()\n",
    "df_imp_ms2ptp.columns = ['Feature', 'Importance']\n",
    "df_imp_ms2ptp['Model'] = 'MS2PTP'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa03fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisation Importance\n",
    "\n",
    "importance_ms2ptp.plot(kind='barh')\n",
    "plt.title(\"Importance des features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8908bb54",
   "metadata": {},
   "source": [
    "###Regroupement modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f085f5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#création dataframe pour stocké resultat R2 par modèle\n",
    "df_results = pd.DataFrame({\n",
    "    'Model': ['MSE1', 'MSE2', 'MS1', 'MS2', 'MS1PTC', 'MS2PTC', 'MS1PTP', 'MS2PTP'],\n",
    "    'R2_train': [r2_train_mse1, r2_train_mse2, r2_train_ms1, r2_train_ms2,\n",
    "                 r2_train_ms1ptc, r2_train_ms2ptc, r2_train_ms1ptp, r2_train_ms2ptp],\n",
    "    'R2_test':  [r2_test_mse1, r2_test_mse2, r2_test_ms1, r2_test_ms2,\n",
    "                 r2_test_ms1ptc, r2_test_ms2ptc, r2_test_ms1ptp, r2_test_ms2ptp]\n",
    "})\n",
    "\n",
    "# Tri par meilleur R2_test\n",
    "df_results = df_results.sort_values(by='R2_test', ascending=False)\n",
    "\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6675ae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualisation comparaison R2 par modèle\n",
    "\n",
    "\n",
    "x = np.arange(len(df_results['Model']))  # position des modèles\n",
    "width = 0.35  # largeur des barres\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "ax.bar(x - width/2, df_results['R2_train'], width, label='R2_train')\n",
    "ax.bar(x + width/2, df_results['R2_test'], width, label='R2_test')\n",
    "\n",
    "ax.set_ylabel('R²')\n",
    "ax.set_xlabel('Modèle')\n",
    "ax.set_title('Comparaison R² Train vs R² Test par modèle')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(df_results['Model'])\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d96eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#création dataframe pour stocké Importance par modèle\n",
    "df_imp = pd.concat([df_imp_mse1, df_imp_mse2, df_imp_ms1, df_imp_ms2,\n",
    "                    df_imp_ms1ptc, df_imp_ms2ptc, df_imp_ms1ptp, df_imp_ms2ptp],axis=0,\n",
    "                   ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e32605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualisation Importance\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='Model', y='Importance', hue='Feature', data=df_imp)\n",
    "plt.title('Importance des features par modèle')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
